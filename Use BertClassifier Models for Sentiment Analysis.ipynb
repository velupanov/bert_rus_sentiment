{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_TF = False\n",
    "USE_DISTILBERT = True\n",
    "DP_MODEL_PATH = './models/bert_base_rus_joined_sent_cased'\n",
    "DP_CONFIG_PATH = './models/bert_base_rus_joined_sent_cased/dp_config.json'\n",
    "PT_BERT_CONFIG_PATH = './models/bert_base_rus_joined_sent_cased_pt/config.json'\n",
    "PT_BERT_MODEL_PATH = './models/bert_base_rus_joined_sent_cased_pt/'\n",
    "PT_DB_CONFIG_PATH = './models/distilbert_rus_joined_sent_cased_pt/config.json'\n",
    "PT_DB_MODEL_PATH = './models/distilbert_rus_joined_sent_cased_pt/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compability\n",
    "def dp_model_wrapper(self, *args):\n",
    "    new_preds = list()\n",
    "    preds = self.__call(*args)\n",
    "    for n_pred in range(len(preds[0])):\n",
    "        new_preds.append({\n",
    "            'label': preds[0][n_pred],\n",
    "            'score': max(preds[1][n_pred]),\n",
    "        })\n",
    "    return new_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if USE_TF:\n",
    "    from deeppavlov.core.common.file import read_json\n",
    "    from deeppavlov import build_model\n",
    "    from deeppavlov import Chainer\n",
    "    # Override standart call to identical output\n",
    "    Chainer.__call = Chainer.__call__\n",
    "    Chainer.__call__ = dp_model_wrapper\n",
    "    \n",
    "    config = read_json(DP_CONFIG_PATH)\n",
    "    config['metadata']['variables']['MODEL_PATH'] = os.path.abspath(DP_MODEL_PATH)\n",
    "    model = build_model(config)\n",
    "elif USE_DISTILBERT:\n",
    "    import torch\n",
    "    from transformers import DistilBertTokenizer, DistilBertConfig, DistilBertForSequenceClassification, TextClassificationPipeline\n",
    "    import json\n",
    "    config = DistilBertConfig.from_pretrained(PT_DB_CONFIG_PATH)\n",
    "    classes_dict = json.load(open(os.path.join(PT_DB_MODEL_PATH, 'classes.dict')))\n",
    "    config.label2id = classes_dict['label2id']\n",
    "    config.id2label = {i[1]:i[0] for i in classes_dict['label2id'].items()}\n",
    "    tokenizer = DistilBertTokenizer.from_pretrained(\n",
    "        PT_DB_MODEL_PATH,\n",
    "        do_lower_case=False,\n",
    "    )\n",
    "    distilbert_model = DistilBertForSequenceClassification.from_pretrained(\n",
    "        PT_DB_MODEL_PATH, \n",
    "        from_tf=False, \n",
    "        config=config, \n",
    "    )\n",
    "    distilbert_model.load_state_dict(torch.load(os.path.join(PT_DB_MODEL_PATH, 'pytorch_model.bin')))\n",
    "    \n",
    "    device = 0 if torch.cuda.is_available() else -1\n",
    "    \n",
    "    model = TextClassificationPipeline(model=distilbert_model, tokenizer=tokenizer, device=device)\n",
    "else:\n",
    "    import torch\n",
    "    from transformers import BertTokenizer, BertConfig, BertForSequenceClassification, TextClassificationPipeline\n",
    "    import json\n",
    "    config = BertConfig.from_pretrained(PT_BERT_CONFIG_PATH)\n",
    "    classes_dict = json.load(open(os.path.join(PT_BERT_MODEL_PATH, 'classes.dict')))\n",
    "    config.label2id = classes_dict['label2id']\n",
    "    config.id2label = {i[1]:i[0] for i in classes_dict['label2id'].items()}\n",
    "    tokenizer = BertTokenizer.from_pretrained(\n",
    "        PT_BERT_MODEL_PATH,\n",
    "        do_lower_case=False,\n",
    "    )\n",
    "    bert_model = BertForSequenceClassification.from_pretrained(\n",
    "        PT_BERT_MODEL_PATH, \n",
    "        from_tf=False, \n",
    "        config=config, \n",
    "    )\n",
    "    bert_model.load_state_dict(torch.load(os.path.join(PT_BERT_MODEL_PATH, 'pytorch_model.bin')))\n",
    "    \n",
    "    device = 0 if torch.cuda.is_available() else -1\n",
    "    \n",
    "    model = TextClassificationPipeline(model=bert_model, tokenizer=tokenizer, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'humor', 'score': 0.9755868911743164},\n",
       " {'label': 'negative', 'score': 0.9982805848121643},\n",
       " {'label': 'neutral', 'score': 0.9273685812950134},\n",
       " {'label': 'positive', 'score': 0.9901606440544128},\n",
       " {'label': 'negative', 'score': 0.9865018725395203},\n",
       " {'label': 'speech', 'score': 0.5939101576805115}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model([\n",
    "    'Скупой платит дважды. Пойду работать к скупому.',\n",
    "    'Такси везет меня на работу. Раздумываю приплатить, чтобы меня втащили на пятый этаж. Лифта то нет :(',\n",
    "    'В настройках телефона пробовали ставить приоритет \"Только 3G\"? Всегда такая сеть там была? #билайн',\n",
    "    'Для всех родных &lt;3 Искренне вас люблю , родные мои :) Скучаю по вам',\n",
    "    'Как же я соскучилась по Никите((( вновь хочу его увидеть!',\n",
    "    'с добреньким утречком и последними днями моих каникул:(',\n",
    "])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dp)",
   "language": "python",
   "name": "dp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
